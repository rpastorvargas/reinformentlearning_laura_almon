{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rpastorvargas/reinformentlearning_laura_almon/blob/main/Transformer_over_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download SMAC dataset\n",
        "!wget https://huggingface.co/datasets/InstaDeepAI/og-marl/resolve/main/core/smac_v1/3m.zip --show-progress"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYmPA-PNJ6JR",
        "outputId": "80746925-4347-4353-c83e-5d1947a334e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-12 17:04:45--  https://huggingface.co/datasets/InstaDeepAI/og-marl/resolve/main/core/smac_v1/3m.zip\n",
            "Resolving huggingface.co (huggingface.co)... 13.33.30.114, 13.33.30.76, 13.33.30.23, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.33.30.114|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.huggingface.co/repos/04/13/04136cbae7cbcbff2267631775f640fd149d53371bf076bef89a954916f62466/4cc6dd8462a1811cdf282a9e2308c8c2367f55d6abaf715389abc4e8182f4727?response-content-disposition=inline%3B+filename*%3DUTF-8%27%273m.zip%3B+filename%3D%223m.zip%22%3B&response-content-type=application%2Fzip&Expires=1723741486&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMzc0MTQ4Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzA0LzEzLzA0MTM2Y2JhZTdjYmNiZmYyMjY3NjMxNzc1ZjY0MGZkMTQ5ZDUzMzcxYmYwNzZiZWY4OWE5NTQ5MTZmNjI0NjYvNGNjNmRkODQ2MmExODExY2RmMjgyYTllMjMwOGM4YzIzNjdmNTVkNmFiYWY3MTUzODlhYmM0ZTgxODJmNDcyNz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=JjqnFLepxpRUhdtkSTJ%7EDJOVCbTxsWy6aDlRoRvCuRCca7BWso8L7ZWz5hhOzZ2i0qSNAabaTQ0Y5m7vCnq%7E1zW6EUBRE5ZM1jBcTtxSCQQJ1qAM2fWILLQb43WqvJmiU3iS3d9aDZ88Zr6s8r1K%7E5O%7EY94et8ldW8XhKbwM9OcstwdhfQ4Kk8QUyPc40yYw48CZ5ZJqPnkMMKTHfY-WAOXhMMGWKqhcm%7Ef6rW%7EyUfhPGv5D9c%7Ey-XJqhA0VT-uFsGmQW9kxhlOqMAhwU7MXPW-oJhapIIUdK%7ERFk%7EHZuJDxD6rwDEQIPBtJ3mOAclbMfiJisCV9jjvdYr5%7EJhQ3yw__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2024-08-12 17:04:46--  https://cdn-lfs-us-1.huggingface.co/repos/04/13/04136cbae7cbcbff2267631775f640fd149d53371bf076bef89a954916f62466/4cc6dd8462a1811cdf282a9e2308c8c2367f55d6abaf715389abc4e8182f4727?response-content-disposition=inline%3B+filename*%3DUTF-8%27%273m.zip%3B+filename%3D%223m.zip%22%3B&response-content-type=application%2Fzip&Expires=1723741486&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMzc0MTQ4Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzA0LzEzLzA0MTM2Y2JhZTdjYmNiZmYyMjY3NjMxNzc1ZjY0MGZkMTQ5ZDUzMzcxYmYwNzZiZWY4OWE5NTQ5MTZmNjI0NjYvNGNjNmRkODQ2MmExODExY2RmMjgyYTllMjMwOGM4YzIzNjdmNTVkNmFiYWY3MTUzODlhYmM0ZTgxODJmNDcyNz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=JjqnFLepxpRUhdtkSTJ%7EDJOVCbTxsWy6aDlRoRvCuRCca7BWso8L7ZWz5hhOzZ2i0qSNAabaTQ0Y5m7vCnq%7E1zW6EUBRE5ZM1jBcTtxSCQQJ1qAM2fWILLQb43WqvJmiU3iS3d9aDZ88Zr6s8r1K%7E5O%7EY94et8ldW8XhKbwM9OcstwdhfQ4Kk8QUyPc40yYw48CZ5ZJqPnkMMKTHfY-WAOXhMMGWKqhcm%7Ef6rW%7EyUfhPGv5D9c%7Ey-XJqhA0VT-uFsGmQW9kxhlOqMAhwU7MXPW-oJhapIIUdK%7ERFk%7EHZuJDxD6rwDEQIPBtJ3mOAclbMfiJisCV9jjvdYr5%7EJhQ3yw__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)... 3.165.102.80, 3.165.102.25, 3.165.102.112, ...\n",
            "Connecting to cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)|3.165.102.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1391810903 (1.3G) [application/zip]\n",
            "Saving to: ‘3m.zip’\n",
            "\n",
            "3m.zip              100%[===================>]   1.30G  23.3MB/s    in 58s     \n",
            "\n",
            "2024-08-12 17:05:44 (23.1 MB/s) - ‘3m.zip’ saved [1391810903/1391810903]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip 3m.zip -d vaults"
      ],
      "metadata": {
        "id": "Ox3WDQhTBu0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la vaults/3m.vlt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8jdSVBuCarW",
        "outputId": "45375be9-eedf-48ee-e20b-c7ef8e7994e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 20\n",
            "drwxrwxr-x 5 root root 4096 Feb 19 08:01 .\n",
            "drwxr-xr-x 3 root root 4096 Aug 12 17:05 ..\n",
            "drwxrwxr-x 3 root root 4096 Feb 19 08:01 Good\n",
            "drwxrwxr-x 3 root root 4096 Feb 19 08:01 Medium\n",
            "drwxrwxr-x 3 root root 4096 Feb 19 08:01 Poor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "! pip install flashbax~=0.1.2\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import flashbax as fbx\n",
        "from flashbax.vault import Vault"
      ],
      "metadata": {
        "id": "zBFWzA3g_b5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vlt = Vault(rel_dir=\"vaults\", vault_name=\"3m.vlt\", vault_uid=\"Good\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYuc_Arj_eW_",
        "outputId": "b846f345-e6d7-4b6d-af89-4384a51f1846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading vault found at /content/vaults/3m.vlt/Good\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = vlt.read()"
      ],
      "metadata": {
        "id": "kwbCBn7r_gL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbGkP8xu_iMI",
        "outputId": "591da5ab-00c8-4b87-91c9-552da2e90930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['experience', 'current_index', 'is_full'])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "offline_data = all_data.experience"
      ],
      "metadata": {
        "id": "-22S1_dN_kcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "offline_data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvf-6XxQ_lsU",
        "outputId": "3eb3b1f6-e626-43fa-88e9-250992d5eb34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['actions', 'infos', 'observations', 'rewards', 'terminals', 'truncations'])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jax.tree_map(lambda x: x.shape, offline_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLdc-WL-_oQT",
        "outputId": "e81cf823-3ec8-42e7-942a-d1e2d75a264d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-e323eeb0b801>:1: DeprecationWarning: jax.tree_map is deprecated: use jax.tree.map (jax v0.4.25 or newer) or jax.tree_util.tree_map (any JAX version).\n",
            "  jax.tree_map(lambda x: x.shape, offline_data)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'actions': (1, 996366, 3),\n",
              " 'infos': {'legals': (1, 996366, 3, 9), 'state': (1, 996366, 48)},\n",
              " 'observations': (1, 996366, 3, 30),\n",
              " 'rewards': (1, 996366, 3),\n",
              " 'terminals': (1, 996366, 3),\n",
              " 'truncations': (1, 996366, 3)}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "offline_data['actions'][0][:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK89crLQhnli",
        "outputId": "38f5404d-0501-4240-aec8-aa727ef03e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[4, 2, 4],\n",
              "       [4, 4, 4],\n",
              "       [4, 4, 4],\n",
              "       [4, 4, 4],\n",
              "       [4, 4, 7],\n",
              "       [8, 6, 7],\n",
              "       [8, 4, 7],\n",
              "       [8, 7, 7],\n",
              "       [7, 7, 7],\n",
              "       [7, 7, 7]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "all_data_np = jax.tree_map(lambda x: np.array(x), all_data)\n",
        "\n",
        "print(all_data_np.experience['actions'][0][:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7aXXLp7FPTk",
        "outputId": "ce42acde-dabb-4522-a20a-a5f629a093f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-7d6d0b9654c8>:2: DeprecationWarning: jax.tree_map is deprecated: use jax.tree.map (jax v0.4.25 or newer) or jax.tree_util.tree_map (any JAX version).\n",
            "  all_data_np = jax.tree_map(lambda x: np.array(x), all_data)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 2 4]\n",
            " [4 4 4]\n",
            " [4 4 4]\n",
            " [4 4 4]\n",
            " [4 4 7]\n",
            " [8 6 7]\n",
            " [8 4 7]\n",
            " [8 7 7]\n",
            " [7 7 7]\n",
            " [7 7 7]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jax.tree_map(lambda x: x.shape, offline_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k06VLFqAMNVa",
        "outputId": "8bf49245-b20b-446e-ed3b-170d125b8b1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-e323eeb0b801>:1: DeprecationWarning: jax.tree_map is deprecated: use jax.tree.map (jax v0.4.25 or newer) or jax.tree_util.tree_map (any JAX version).\n",
            "  jax.tree_map(lambda x: x.shape, offline_data)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'actions': (1, 996366, 3),\n",
              " 'infos': {'legals': (1, 996366, 3, 9), 'state': (1, 996366, 48)},\n",
              " 'observations': (1, 996366, 3, 30),\n",
              " 'rewards': (1, 996366, 3),\n",
              " 'terminals': (1, 996366, 3),\n",
              " 'truncations': (1, 996366, 3)}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "actions = all_data_np.experience['actions'][0]\n",
        "infos = all_data_np.experience['infos']\n",
        "infos_legals = infos['legals'][0]\n",
        "infos_state = infos['state'][0]\n",
        "observations = all_data_np.experience['observations'][0]\n",
        "rewards = all_data_np.experience['rewards'][0]\n",
        "terminals = all_data_np.experience['terminals'][0]\n",
        "truncations = all_data_np.experience['truncations'][0]"
      ],
      "metadata": {
        "id": "NtL5oVl3MEiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(actions), actions[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQSD-8IXNt9w",
        "outputId": "8a31a530-9f73-4943-8eea-37f1f9889681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(996366, array([4, 2, 4], dtype=int32))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data = []\n",
        "# episode = {\n",
        "#     'observations': [],\n",
        "#     'actions': [],\n",
        "#     'rewards': []\n",
        "# }\n",
        "\n",
        "# for i in range(len(actions)):\n",
        "#     episode['observations'].append(observations[i])\n",
        "#     episode['actions'].append(actions[i])\n",
        "#     episode['rewards'].append(rewards[i])\n",
        "\n",
        "#     # Check if it is the end of an episode\n",
        "#     if terminals[i].all() == 1:\n",
        "#         data.append(episode)\n",
        "#         episode = {\n",
        "#             'observations': [],\n",
        "#             'actions': [],\n",
        "#             'rewards': []\n",
        "#         }"
      ],
      "metadata": {
        "id": "Rdq3mjHxPABg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb8XIn7tT8Dm",
        "outputId": "eb1030b6-65d7-40ba-94e9-91351a8e97a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43559"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "available_actions = []\n",
        "for i in range(len(actions)):\n",
        "    for a in actions[i]:\n",
        "        if a not in available_actions:\n",
        "            available_actions.append(a)\n",
        "available_actions.sort()\n",
        "print(available_actions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQqDvtr-ipgN",
        "outputId": "3bc5ab21-d72a-440e-d6a0-3f50b768e996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import GPT2Model, GPT2Config\n",
        "\n",
        "class DecisionTransformer(nn.Module):\n",
        "    def __init__(self, observation_dim, action_dim, max_length=100):\n",
        "        super(DecisionTransformer, self).__init__()\n",
        "\n",
        "        self.observation_dim = observation_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.max_length = max_length\n",
        "\n",
        "        config = GPT2Config(vocab_size=1, n_positions=max_length, n_ctx=max_length, n_embd=256, n_layer=4, n_head=4)\n",
        "        self.transformer = GPT2Model(config)\n",
        "\n",
        "        self.embed_observation = nn.Linear(observation_dim, 256)\n",
        "        self.embed_action = nn.Linear(action_dim, 256)\n",
        "        self.embed_reward = nn.Linear(3, 256)\n",
        "\n",
        "        self.action_head = nn.Linear(256, 9)\n",
        "\n",
        "    def forward(self, observations, actions, rewards):\n",
        "        # Embed each component\n",
        "        obs_embeds = self.embed_observation(observations)\n",
        "        act_embeds = self.embed_action(actions)\n",
        "        rew_embeds = self.embed_reward(rewards)\n",
        "\n",
        "        # Concatenate along the sequence dimension\n",
        "        transformer_input = torch.cat([obs_embeds, act_embeds, rew_embeds], dim=0)\n",
        "\n",
        "        # Pass through transformer\n",
        "        transformer_output = self.transformer(inputs_embeds=transformer_input)\n",
        "\n",
        "        # Predict actions from the transformer output\n",
        "        predicted_actions = self.action_head(transformer_output.last_hidden_state)\n",
        "\n",
        "        return predicted_actions"
      ],
      "metadata": {
        "id": "56MXETQpNAR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(observations), len(observations[0]), len(observations[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79jfy57zVMST",
        "outputId": "29fe8983-2c12-484d-ff45-933f3096210f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(996366, 3, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(actions), actions[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkK3HacpVh2h",
        "outputId": "64ce9542-cdf8-4573-9c0b-ce3cc85dd148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(996366, array([4, 2, 4], dtype=int32))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# n_agents = 3\n",
        "# data = []\n",
        "\n",
        "# for i in range(len(actions)):\n",
        "#     step = {\n",
        "#         'observations': np.array([]),\n",
        "#         'actions': [],\n",
        "#         'rewards': []\n",
        "#     }\n",
        "#     for a in range(n_agents):\n",
        "#         step['observations'] = np.append(step['observations'], observations[i][a])\n",
        "#         step['actions'].append(actions[i][a])\n",
        "#         step['rewards'].append(rewards[i][a])\n",
        "#     data.append(step)"
      ],
      "metadata": {
        "id": "6ru2GPmdtmi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# n_agents = 3\n",
        "# data = []\n",
        "\n",
        "# for i in range(len(actions)):\n",
        "#     step = {\n",
        "#         'observations': np.array([]),\n",
        "#         'actions': [],\n",
        "#         'rewards': []\n",
        "#     }\n",
        "#     step['observations'] = np.append(step['observations'], observations[i][a])\n",
        "#     step['actions'].append(actions[i][a])\n",
        "#     step['rewards'].append(rewards[i][a])\n",
        "#     data.append(step)"
      ],
      "metadata": {
        "id": "yA25iKuN1_VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import DecisionTransformerModel, DecisionTransformerConfig\n",
        "\n",
        "# n_agents = 3\n",
        "# observation_dim = 30 * n_agents  # 30 * 3 = 90\n",
        "# action_dim = 1 * n_agents  # 1 * 3 = 3\n",
        "\n",
        "# # Configurar el modelo con los parámetros deseados\n",
        "# config = DecisionTransformerConfig(\n",
        "#     state_dim=observation_dim,  # Dimensión de las observaciones\n",
        "#     act_dim=action_dim,         # Dimensión de las acciones\n",
        "#     max_length=100,             # Longitud máxima de la secuencia\n",
        "#     hidden_size=128,            # Tamaño de las capas ocultas\n",
        "#     num_attention_heads=4,      # Número de cabezas de atención\n",
        "#     num_layers=2                # Número de capas en el transformador\n",
        "# )\n",
        "\n",
        "# model = DecisionTransformerModel(config)"
      ],
      "metadata": {
        "id": "qGCHiF0F0HRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ITERATE THROUGH EVERY STEP\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "# Initialize the model\n",
        "n_agents = 3\n",
        "observation_dim = 30 * n_agents  # 30 * 3 = 90\n",
        "action_dim = 1 * n_agents  # 1 * 3 = 3\n",
        "model = DecisionTransformer(observation_dim, action_dim)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()  # Or MSELoss for discrete actions\n",
        "\n",
        "# Training of the model\n",
        "def train_model(model, num_epochs=10):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        for i in range(len(actions)):\n",
        "            #observations_tensor = torch.tensor(observations[i], dtype=torch.float32)\n",
        "            observations_tensor = torch.from_numpy(observations[i]).reshape(1,1,observation_dim).to(dtype=torch.float32)\n",
        "            #actions_tensor = torch.tensor(actions[i], dtype=torch.float32)\n",
        "            actions_tensor = torch.from_numpy(actions[i]).reshape(1,1,action_dim).to(dtype=torch.float32)\n",
        "            #rewards_tensor = torch.tensor(rewards[i], dtype=torch.float32)\n",
        "            rewards_tensor = torch.from_numpy(rewards[i]).reshape(1,1,n_agents).to(dtype=torch.float32)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            predicted_actions = model(observations_tensor, actions_tensor, rewards_tensor)\n",
        "\n",
        "            actions_tensor = actions_tensor[0][0].type(torch.LongTensor)\n",
        "            predicted_actions = torch.movedim(predicted_actions, 1, 0)[0]\n",
        "\n",
        "            #predicted_actions = torch.movedim(predicted_actions, (1,2), (0,1))\n",
        "\n",
        "            loss = criterion(predicted_actions, actions_tensor)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_item = loss.item()\n",
        "            epoch_loss += loss_item\n",
        "\n",
        "            if i % 10000 == 0:\n",
        "                print(f\"i = {i}, Loss mean = {epoch_loss / (i+1)}\")\n",
        "\n",
        "        print()\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(actions)}\")\n",
        "        print()\n",
        "\n",
        "train_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 912
        },
        "id": "FE40Rd7-roaW",
        "outputId": "f710853e-9ea0-4f3d-c8e3-45bf0e61b77e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0, Loss mean = 2.579193592071533\n",
            "i = 10000, Loss mean = 1.046469236371422\n",
            "i = 20000, Loss mean = 0.9308419639123516\n",
            "i = 30000, Loss mean = 0.8766793993596816\n",
            "i = 40000, Loss mean = 0.8452466902257201\n",
            "i = 50000, Loss mean = 0.8218077601701881\n",
            "i = 60000, Loss mean = 0.8071355568506285\n",
            "i = 70000, Loss mean = 0.79727253361365\n",
            "i = 80000, Loss mean = 0.7859498731437795\n",
            "i = 90000, Loss mean = 0.7773356637013724\n",
            "i = 100000, Loss mean = 0.7708500015774488\n",
            "i = 110000, Loss mean = 0.7644955440236774\n",
            "i = 120000, Loss mean = 0.7596613824183247\n",
            "i = 130000, Loss mean = 0.7550380558939842\n",
            "i = 140000, Loss mean = 0.7508275735462329\n",
            "i = 150000, Loss mean = 0.7468818002142852\n",
            "i = 160000, Loss mean = 0.7428667532880868\n",
            "i = 170000, Loss mean = 0.7398068413058011\n",
            "i = 180000, Loss mean = 0.7370815539342033\n",
            "i = 190000, Loss mean = 0.7340212618863475\n",
            "i = 200000, Loss mean = 0.7313548147219012\n",
            "i = 210000, Loss mean = 0.7291767650519554\n",
            "i = 220000, Loss mean = 0.7272456751459798\n",
            "i = 230000, Loss mean = 0.7246408978544685\n",
            "i = 240000, Loss mean = 0.7227665410668739\n",
            "i = 250000, Loss mean = 0.7213089908841717\n",
            "i = 260000, Loss mean = 0.720637202657901\n",
            "i = 270000, Loss mean = 0.7195416300354653\n",
            "i = 280000, Loss mean = 0.7185332099205567\n",
            "i = 290000, Loss mean = 0.7173755087871898\n",
            "i = 300000, Loss mean = 0.7160874055158566\n",
            "i = 310000, Loss mean = 0.7151592995426626\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-75dfc7abbec4>\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-75dfc7abbec4>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, num_epochs)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m#predicted_actions = torch.movedim(predicted_actions, (1,2), (0,1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1186\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3084\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3086\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, \"my-transformer-model\")"
      ],
      "metadata": {
        "id": "nA6YkZutjTMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "erC1TfmlM4qy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}